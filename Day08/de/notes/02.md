# Pandas: Data Cleaning & Preprocessing (Beginner to Advanced)

## 1. Introduction
Data cleaning and preprocessing are essential steps in any data analysis workflow. Pandas provides powerful tools to handle missing data, remove duplicates, convert data types, handle outliers, and more.

---

## 2. Handling Missing Data

### 2.1 Detecting Missing Values
```python
df.isnull()           # Boolean DataFrame: True for NaNs
df.isnull().sum()     # Count missing values per column
df.notnull()          # Opposite of isnull()
```

### 2.2 Removing Missing Values
```python
df.dropna()                   # Drop rows with any NaN
df.dropna(axis=1)             # Drop columns with any NaN
df.dropna(how='all')          # Drop rows where all values are NaN
df.dropna(thresh=2)           # Keep rows with at least 2 non-NaN values
df.dropna(subset=['col1'])    # Drop rows where 'col1' is NaN
```

### 2.3 Filling Missing Values
```python
df.fillna(0)                          # Replace NaN with 0
df.fillna({'col1': 0, 'col2': 1})     # Replace NaN in specific columns
df.fillna(method='ffill')             # Forward fill
df.fillna(method='bfill')             # Backward fill
df.fillna(df.mean())                  # Fill with mean (numeric columns)
df.interpolate()                      # Interpolate missing values
```

---

## 3. Removing Duplicates

```python
df.duplicated()               # Boolean Series: True for duplicates
df.drop_duplicates()          # Remove duplicate rows
df.drop_duplicates(subset=['col1'])  # Remove duplicates based on 'col1'
df.drop_duplicates(keep='last')      # Keep last occurrence
```

---

## 4. Data Type Conversion

```python
df['col'] = df['col'].astype(int)         # Convert to integer
df['col'] = pd.to_numeric(df['col'])      # Convert to numeric, errors='coerce'
df['date'] = pd.to_datetime(df['date'])   # Convert to datetime
df['col'] = df['col'].astype('category')  # Convert to category
```

---

## 5. String Operations

```python
df['col'].str.lower()             # Convert to lowercase
df['col'].str.upper()             # Convert to uppercase
df['col'].str.strip()             # Remove whitespace
df['col'].str.replace('a', 'b')   # Replace characters
df['col'].str.contains('abc')     # Boolean mask for substring
df['col'].str.extract('(\d+)')    # Extract numbers using regex
```

---

## 6. Handling Outliers

```python
df[(df['col'] < lower) | (df['col'] > upper)]   # Filter outliers
df['col'].clip(lower, upper)                    # Cap values
```

---

## 7. Mapping & Replacing Values

```python
df['col'].map({'A': 1, 'B': 2})         # Map values
df['col'].replace({'A': 1, 'B': 2})    # Replace values
df.replace(np.nan, 0)                  # Replace all NaN with 0
```

---

## 8. Renaming Columns & Index

```python
df.rename(columns={'old': 'new'}, inplace=True)
df.rename(index={0: 'first'}, inplace=True)
df.columns = ['A', 'B', 'C']           # Rename all columns
```

---

## 9. Filtering & Selecting Data

```python
df[df['col'] > 0]                      # Filter rows
df.query('col > 0 and col2 < 5')       # Query method
df.loc[0:5, ['col1', 'col2']]          # Select by label
df.iloc[0:5, 0:2]                      # Select by position
```

---

## 10. Applying Functions

```python
df.apply(np.sqrt)                      # Apply function to all columns
df['col'].apply(lambda x: x+1)         # Apply function to column
df.applymap(str)                       # Apply function to all elements
```

---

## 11. Binning & Discretization

```python
pd.cut(df['col'], bins=3)              # Bin into 3 equal-width bins
pd.qcut(df['col'], q=4)                # Bin into 4 quantiles
```

---

## 12. Encoding Categorical Variables

```python
pd.get_dummies(df['col'])              # One-hot encoding
df['col'].astype('category').cat.codes # Label encoding
```

---

## 13. Scaling & Normalization

```python
from sklearn.preprocessing import MinMaxScaler, StandardScaler

scaler = MinMaxScaler()
df[['col1', 'col2']] = scaler.fit_transform(df[['col1', 'col2']])

scaler = StandardScaler()
df[['col1', 'col2']] = scaler.fit_transform(df[['col1', 'col2']])
```

---

## 14. Combining DataFrames

```python
pd.concat([df1, df2], axis=0)          # Concatenate rows
pd.concat([df1, df2], axis=1)          # Concatenate columns
df1.merge(df2, on='key')               # Merge on key column
```

---

## 15. Saving & Loading Cleaned Data

```python
df.to_csv('cleaned.csv', index=False)
df = pd.read_csv('cleaned.csv')
df.to_excel('cleaned.xlsx')
df = pd.read_excel('cleaned.xlsx')
```

---

## 16. Advanced: Custom Cleaning

- **Custom Functions:** Use `apply`, `map`, or `applymap` for complex cleaning.
- **Pipelines:** Chain multiple operations for reproducible workflows.
- **Automated Profiling:** Use `pandas_profiling` or `sweetviz` for EDA.

---

## 17. Useful Tips

- Always inspect your data: `df.info()`, `df.describe()`, `df.head()`
- Visualize missing data: `import missingno as msno; msno.matrix(df)`
- Document your cleaning steps for reproducibility.

---

## 18. References

- [Pandas Documentation](https://pandas.pydata.org/docs/)
- [Pandas User Guide: Working with Missing Data](https://pandas.pydata.org/pandas-docs/stable/user_guide/missing_data.html)
- [Pandas Cheat Sheet](https://pandas.pydata.org/Pandas_Cheat_Sheet.pdf)

